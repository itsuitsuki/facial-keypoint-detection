{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "tree = ET.parse('ibug_300W_large_face_landmark_dataset/labels_ibug_300W_train.xml')\n",
    "root = tree.getroot()\n",
    "root_dir = 'ibug_300W_large_face_landmark_dataset'\n",
    "\n",
    "bboxes = [] # face bounding box used to crop the image\n",
    "landmarks = [] # the facial keypoints/landmarks for the whole training dataset\n",
    "img_filenames = [] # the image names for the whole dataset\n",
    "\n",
    "for filename in root[2]:\n",
    "\timg_filenames.append(os.path.join(root_dir, filename.attrib['file']))\n",
    "\tbox = filename[0].attrib\n",
    "\t# x, y for the top left corner of the box, w, h for box width and height\n",
    "\tbboxes.append([box['left'], box['top'], box['width'], box['height']]) \n",
    "\n",
    "\tlandmark = []\n",
    "\tfor num in range(68):\n",
    "\t\tx_coordinate = int(filename[0][num].attrib['x'])\n",
    "\t\ty_coordinate = int(filename[0][num].attrib['y'])\n",
    "\t\tlandmark.append([x_coordinate, y_coordinate])\n",
    "\tlandmarks.append(landmark) # relative? \n",
    "\n",
    "landmarks = np.array(landmarks).astype('float32')\n",
    "bboxes = np.array(bboxes).astype('float32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IbugTrainingHeatmapDataset(Dataset):\n",
    "    def __init__(self, img_filenames, bboxes, landmarks, normalize=True, basic_transform=None, albu_transform=None, sigma=1):\n",
    "        self.img_filenames = img_filenames\n",
    "        self.bboxes = bboxes\n",
    "        self.landmarks = landmarks\n",
    "        self.basic_transform = basic_transform # resize, totensor, normalize\n",
    "        self.albu_transform = albu_transform # albumentations\n",
    "        self.normalize = normalize\n",
    "        self.sigma = sigma\n",
    "        if not self.normalize:\n",
    "            print('Not normalizing the image')\n",
    "        if not self.basic_transform:\n",
    "            print('No basic transformation')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_filenames[idx]\n",
    "        opened_img = Image.open(img_path).convert('L') # range [0, 255] # shape (H, W)\n",
    "        bounding_box = self.bboxes[idx]\n",
    "        landmark_ori = self.landmarks[idx] # (68, 2)\n",
    "        x, y, w, h = bounding_box # left, top, width, height\n",
    "        cropped_by_bbox = opened_img.crop((x, y, x+w, y+h)) # shape (h, w)\n",
    "\n",
    "        cropped_by_bbox = np.array(cropped_by_bbox) # range [0, 255] # shape (H, W)\n",
    "        cropped_by_bbox = np.expand_dims(cropped_by_bbox, axis=2) # shape (H, W, 1)\n",
    "        # to float32\n",
    "        cropped_by_bbox = cropped_by_bbox.astype(np.float32) # shape (H, W, C)\n",
    "        if self.normalize:\n",
    "            cropped_by_bbox = cropped_by_bbox / 255.0 - 0.5 # range [-0.5, 0.5]\n",
    "            # print(cropped_by_bbox.dtype)\n",
    "        # adjust the landmark\n",
    "        # landmark2 = landmark - [x, y] # FIXME: broadcast?\n",
    "        landmark = np.zeros_like(landmark_ori)\n",
    "        landmark[:, 0] = landmark_ori[:, 0] - x\n",
    "        landmark[:, 1] = landmark_ori[:, 1] - y\n",
    "        # assert np.all(landmark == landmark2)\n",
    "        \n",
    "        \n",
    "        # to relative coordinates\n",
    "        if self.albu_transform:\n",
    "            transformed = self.albu_transform(image=cropped_by_bbox, keypoints=landmark)\n",
    "            tfed_im = transformed['image']\n",
    "            landmark = transformed['keypoints']\n",
    "        else:\n",
    "            tfed_im = cropped_by_bbox # (C, H, W)\n",
    "            \n",
    "        landmark = torch.tensor(landmark) # shape: (68, 2)\n",
    "        \n",
    "        \n",
    "        # relative coordinates [0, 1]\n",
    "        landmark[:, 0] = landmark[:, 0] / w * 224\n",
    "        landmark[:, 1] = landmark[:, 1] / h * 224\n",
    "        # print(tfed_im.shape, w, h)\n",
    "        # tfed_im = torch.tensor(tfed_im)\n",
    "        # print(tfed_im.shape)\n",
    "        if self.basic_transform:\n",
    "            tfed_im = self.basic_transform(tfed_im) # tfed_im: (C, 224, 224)\n",
    "        else:\n",
    "            tfed_im = torch.tensor(tfed_im)\n",
    "        # heatmap should be (68, 224, 224)\n",
    "        heatmap = self._gaussian_heatmap(landmark, 224, 224, 68)\n",
    "        heatmap = torch.tensor(heatmap)\n",
    "        heatmap = heatmap.float()\n",
    "        return tfed_im, heatmap, landmark # tfed_im: (C=1, 224, 224), heatmap: (68, 224, 224), landmark: (68, 2)\n",
    "    \n",
    "    def _gaussian_heatmap(self, landmark, height, width, channels):\n",
    "        # gaussian density\n",
    "        heatmap = np.zeros((channels, height, width))\n",
    "        # landmark: (68, 2)\n",
    "        # for i in range(channels): \n",
    "        #     x = landmark[i, 0]\n",
    "        #     y = landmark[i, 1]\n",
    "        #     density = np.zeros((height, width))\n",
    "        #     for j in range(height):\n",
    "        #         for k in range(width):\n",
    "        #             density[j, k] = np.exp(-((j - x)**2 + (k - y)**2) / (2 * sigma**2))\n",
    "        #     zero_heatmap[i] = density\n",
    "        for i in range(channels):\n",
    "            x = landmark[i, 0]\n",
    "            y = landmark[i, 1]\n",
    "            for j in range(height):\n",
    "                for k in range(width):\n",
    "                    heatmap[i, j, k] = np.exp(-((j - x)**2 + (k - y)**2) / (2 * self.sigma**2))\n",
    "            # normalize s.t. the sum of each heatmap is 1\n",
    "            heatmap[i] = heatmap[i] / np.sum(heatmap[i])\n",
    "        return heatmap\n",
    "    \n",
    "    \n",
    "basic_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)), # From (C, H, W) to (C, 224, 224)\n",
    "    # grayscale\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Affine(rotate=(-15, 15), translate_percent={'x': 0.1, 'y': 0.1}),\n",
    "    A.GaussNoise(p=0.5), # DO WE NEED THIS?\n",
    "    A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    ToTensorV2(),\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "dataset = IbugTrainingHeatmapDataset(img_filenames, bboxes, landmarks, basic_transform=basic_transform, albu_transform=transform, normalize=True, sigma=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Model Architecture\n",
    "We use a UNet predicting the probability density heatmap (shape [68, 224, 224]) of the face landmarks, and then find the expected position of the landmarks w.r.t. the heatmap,\n",
    "i.e. a pixelwise classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# load unet\n",
    "from unet import PixelwiseClassificationUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PixelwiseClassificationUNet(1, 68).to(device)\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function, between predicted heatmap and ground truth heatmap\n",
    "# need mae\n",
    "from torch.nn.functional import mse_loss, binary_cross_entropy_with_logits, l1_loss\n",
    "from tqdm import tqdm\n",
    "LR = 1e-3\n",
    "BS = 32\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "num_epochs = 10\n",
    "# loader\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_to_landmarks(heatmap):\n",
    "    # heatmap: (B, 68, 224, 224) -> (B, 68, 2)\n",
    "    landmarks = []\n",
    "    for i in range(heatmap.shape[0]):\n",
    "        hm = heatmap[i] # (68, 224, 224)\n",
    "        landmark = np.zeros((68, 2))\n",
    "        for j in range(68):\n",
    "            hm_j = hm[j] # (224, 224)\n",
    "            x, y = np.unravel_index(hm_j.argmax(), hm_j.shape)\n",
    "            landmark[j, 0] = x\n",
    "            landmark[j, 1] = y\n",
    "        landmarks.append(landmark)\n",
    "    landmarks = np.array(landmarks)\n",
    "    return torch.tensor(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    loop.set_description(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    for i, (images, heatmaps, _) in loop:\n",
    "        images = images.to(device) # shape: (B, C, H, W)\n",
    "        heatmaps = heatmaps.to(device) # shape: (B, 68, H, W)\n",
    "        # landmarks = landmarks.to(device) # shape: (B, 68, 2)\n",
    "        # Forward pass\n",
    "        logits = model(images) # shape: (B, 68, H, W)\n",
    "        # should mean over B*68\n",
    "        loss = binary_cross_entropy_with_logits(logits, heatmaps)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix(train_loss=loss.item())\n",
    "    train_loss /= len(train_loader)\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    loop = tqdm(enumerate(val_loader), total=len(val_loader), leave=False)\n",
    "    loop.set_description(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "    with torch.no_grad():\n",
    "        for i, (images, heatmaps, _) in enumerate(val_loader):\n",
    "            images = images.to(device) # shape: (B, C, H, W)\n",
    "            heatmaps = heatmaps.to(device) # shape: (B, 68, H, W)\n",
    "            landmarks = landmarks.to(device) # shape: (B, 68, 2)\n",
    "            # Forward pass\n",
    "            logits = model(images) # shape: (B, 68, H, W)\n",
    "            # find mae between expected and predicted landmarks\n",
    "            # aggregate over H and W\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            predicted_landmarks = heatmap_to_landmarks(probs)\n",
    "            # should mean over B*68\n",
    "            loss = binary_cross_entropy_with_logits(logits, heatmaps)\n",
    "            val_loss += loss.item()\n",
    "            loop.set_postfix(val_loss=loss.item())\n",
    "    val_loss /= len(val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
